{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DanB1421/DATA602/blob/main/Brilliant_Problem_Set_12-qederf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZ6ssl1-zD8s"
      },
      "source": [
        "\n",
        "In the Google shared drive (/602/data), the file enron.txt is a subset of the Enron Corpus, a collection of over 500,000 emails from senior management of Enron Corporation leading to its collapse in 2001.  The subset comprises the text of about 15,000 emails available through the TensorFlow Data Set (TFDS) source aeslc (annotated Enron Subject Line Corpus).\n",
        "\n",
        "Using this dataset, construct a neural net that will generate 50 random characters, beginning with the sequence \\verb!The!, that are generated from the distribution of text in the file.\n",
        "\n",
        "This exercise can be replicated using any of the following sources in the texts and documentation:\n",
        "\n",
        "* **Raschka** - Character-level language modeling in TensorFlow, pages 600-613\n",
        "* **GÃ¨ron** - Generating Shakespearean Text Using a Character RNN, pages 526-534\n",
        "* **TensorFlow documentation** [Text Generation with an RNN](https://www.tensorflow.org/text/tutorials/text_generation)\n",
        "\n",
        "\n",
        "Adjust the temperature ($\\alpha$ in Raschka) to avoid repeating text.  Using a GPU runtime to fit the model is advised, which may still require several hours to train.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9YSFsVRzCY9",
        "outputId": "e3726678-905e-47f0-e5f0-35b4ce5cbea1"
      },
      "source": [
        "from google.colab import drive\n",
        "import numpy as np\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tStYGXanzEWb"
      },
      "source": [
        "#read the file content into the variable corpus\n",
        "with open('/content/drive/Shareddrives/DS602-F22/Data/enron.txt', 'r', encoding='utf8') as f:\n",
        "  corpus = f.read()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import os\n",
        "import time"
      ],
      "metadata": {
        "id": "j41Z4kBzxKyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Length of text: {len(corpus)} characters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuT3COD4xmkJ",
        "outputId": "d7a0ad5a-2993-42cd-88be-7100035e5bb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text: 14307407 characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(corpus[:250])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxV9KZkLxuIO",
        "outputId": "907964d3-dbd1-45a4-dfa7-9475c878f2d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Greg and Mark:  Attached is a draft of the very short story that will accompany your profiles in Enron Business.\n",
            "(PR management has approved.)\n",
            "The purpose is simply to introduce you and quickly address the issue that's on everyone's mind, the stock p\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = sorted(set(corpus))\n",
        "print(f'{len(vocab)} unique characters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMntpOfexxyD",
        "outputId": "dcf14d21-4e2b-47cd-d284-f4d9fb1a3e76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "96 unique characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_texts = ['abcdefg', 'xyz']\n",
        "\n",
        "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
        "chars"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XX333xDKx3Ex",
        "outputId": "a04a2dae-4c89-466b-bbce-7709f0235756"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids_from_chars = tf.keras.layers.StringLookup(\n",
        "    vocabulary=list(vocab), mask_token=None)"
      ],
      "metadata": {
        "id": "ydZGeVFwyJNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ids = ids_from_chars(chars)\n",
        "ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTnSP-ZHyLjE",
        "outputId": "cca716bb-7cc6-4e42-f953-aa3ade015784"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[67, 68, 69, 70, 71, 72, 73], [90, 91, 92]]>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars_from_ids = tf.keras.layers.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
      ],
      "metadata": {
        "id": "VrIIpGlJyZyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chars = chars_from_ids(ids)\n",
        "chars"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqlGXsPzyb-x",
        "outputId": "ea9dac49-134b-4e0a-e14c-c5dd09cd3d10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.strings.reduce_join(chars, axis=-1).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxxgVWNEyfB9",
        "outputId": "09a1e847-c63e-4371-86bc-58027b8ea586"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'abcdefg', b'xyz'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def text_from_ids(ids):\n",
        "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ],
      "metadata": {
        "id": "tqmvblnAzELt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(corpus, 'UTF-8'))\n",
        "all_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jn9jS1O2zJsB",
        "outputId": "ca1ba250-cf2e-4816-d5a4-d0eafd75eead"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(14307407,), dtype=int64, numpy=array([42, 84, 71, ..., 67, 85,  2])>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n",
        "for ids in ids_dataset.take(10):\n",
        "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHPsnPvfziXS",
        "outputId": "1bba82c6-c333-482b-8362-230c26465504"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "G\n",
            "r\n",
            "e\n",
            "g\n",
            " \n",
            "a\n",
            "n\n",
            "d\n",
            " \n",
            "M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 50"
      ],
      "metadata": {
        "id": "myuq1wnrz8Is"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(1):\n",
        "  print(chars_from_ids(seq))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfqESB-gz5SJ",
        "outputId": "1e30da79-603a-4b2d-d3a7-a82fd116dba7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'G' b'r' b'e' b'g' b' ' b'a' b'n' b'd' b' ' b'M' b'a' b'r' b'k' b':'\n",
            " b' ' b' ' b'A' b't' b't' b'a' b'c' b'h' b'e' b'd' b' ' b'i' b's' b' '\n",
            " b'a' b' ' b'd' b'r' b'a' b'f' b't' b' ' b'o' b'f' b' ' b't' b'h' b'e'\n",
            " b' ' b'v' b'e' b'r' b'y' b' ' b's' b'h' b'o'], shape=(51,), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for seq in sequences.take(5):\n",
        "  print(text_from_ids(seq).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlH0mY3g0CNc",
        "outputId": "18fd0099-7ae6-4a86-db41-f7486cfebd67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'Greg and Mark:  Attached is a draft of the very sho'\n",
            "b'rt story that will accompany your profiles in Enron'\n",
            "b' Business.\\n(PR management has approved.)\\nThe purpos'\n",
            "b'e is simply to introduce you and quickly address th'\n",
            "b\"e issue that's on everyone's mind, the stock price.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text"
      ],
      "metadata": {
        "id": "O0XMsPhf0Te-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_input_target(list(\"Tensorflow\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCkY6G0n0U4c",
        "outputId": "fd0e5a62-59ce-46f5-918c-9d276f1e89db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = sequences.map(split_input_target)"
      ],
      "metadata": {
        "id": "oIB2R69_0qkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "    print(\"Target:\", text_from_ids(target_example).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByOdc8890sS5",
        "outputId": "627feabc-5ae7-426f-a932-8a4915f5b5bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : b'Greg and Mark:  Attached is a draft of the very sh'\n",
            "Target: b'reg and Mark:  Attached is a draft of the very sho'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58bmmj2e3MCw",
        "outputId": "0c0d18a8-ef43-418d-9562-5eb21a4c7d7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 50), dtype=tf.int64, name=None), TensorSpec(shape=(64, 50), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Length of the vocabulary in StringLookup Layer\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ],
      "metadata": {
        "id": "lCebHIY_3SRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x"
      ],
      "metadata": {
        "id": "5S65naQV3WCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyModel(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ],
      "metadata": {
        "id": "y7rMFg6X3afn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qL5-cml63e7W",
        "outputId": "b666a6c4-ef7d-412e-a438-a7bc55fd992b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 50, 97) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUt4ecH53ldE",
        "outputId": "af158146-e226-4099-b55c-65f653809059"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       multiple                  24832     \n",
            "                                                                 \n",
            " gru (GRU)                   multiple                  3938304   \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  99425     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,062,561\n",
            "Trainable params: 4,062,561\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
      ],
      "metadata": {
        "id": "Dlm6cRS43pRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfTRCLGX3r7Z",
        "outputId": "aacc7729-e8e1-4b19-f679-f900bd1ed409"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([63, 90, 67, 60, 84, 92, 79, 16, 71, 12, 95,  0, 41, 55, 41, 79, 25,\n",
              "       38, 20, 75,  3, 28, 14, 93, 42, 51, 27, 26,  3, 85, 64, 21,  2, 33,\n",
              "       41, 91, 93, 22, 68, 49,  2, 78,  6, 57, 76,  4, 68, 62, 22, 51])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNHK04Cr3uqq",
        "outputId": "86caa304-848d-4da5-f7e2-08c2a7add4d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:\n",
            " b' rules are and guess what we can expect.\\nInstead h'\n",
            "\n",
            "Next Char Predictions:\n",
            " b'\\\\xaYrzm-e)}[UNK]FTFm6C1i 9+{GP87 s]2\\n>Fy{3bN\\nl#Vj!b[3P'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", example_batch_mean_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBfZGyxW31qY",
        "outputId": "02c031fb-8d47-4d36-e599-31f35129b300"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction shape:  (64, 50, 97)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         tf.Tensor(4.5728498, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.exp(example_batch_mean_loss).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drTEWL8L37iF",
        "outputId": "e8184d22-143d-4d4d-b8fe-e0f91346029a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "96.819626"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "metadata": {
        "id": "3vJOg73V3-_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "metadata": {
        "id": "YRF5Nl7A4BUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTT4eCN64DWx",
        "outputId": "43b8dbed-5170-44bd-c929-14b0f3901004"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "4383/4383 [==============================] - 64s 14ms/step - loss: 1.4061\n",
            "Epoch 2/10\n",
            "4383/4383 [==============================] - 57s 13ms/step - loss: 1.1337\n",
            "Epoch 3/10\n",
            "4383/4383 [==============================] - 57s 13ms/step - loss: 1.0897\n",
            "Epoch 4/10\n",
            "4383/4383 [==============================] - 57s 13ms/step - loss: 1.0701\n",
            "Epoch 5/10\n",
            "4383/4383 [==============================] - 58s 13ms/step - loss: 1.0612\n",
            "Epoch 6/10\n",
            "4383/4383 [==============================] - 57s 13ms/step - loss: 1.0583\n",
            "Epoch 7/10\n",
            "4383/4383 [==============================] - 57s 13ms/step - loss: 1.0588\n",
            "Epoch 8/10\n",
            "4383/4383 [==============================] - 57s 13ms/step - loss: 1.0621\n",
            "Epoch 9/10\n",
            "4383/4383 [==============================] - 57s 13ms/step - loss: 1.0682\n",
            "Epoch 10/10\n",
            "4383/4383 [==============================] - 57s 13ms/step - loss: 1.0755\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states"
      ],
      "metadata": {
        "id": "JJGJoHHJ6KVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars, temperature=0.5)"
      ],
      "metadata": {
        "id": "F4s9xbHV6MmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['The'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xR3VYwTV6O98",
        "outputId": "5f2b3fc3-8fbb-467d-fc18-9dddd13970a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The contact will be contacted by the end of the day.\n",
            "If you have any questions, please contact me at Caroline in your conference call that will be available to arrive at a value of the formal application with the same to subsidize a payment of the most possible to continue to be undertaken in the event of such better start time, and if the first notice of the program is in a process of successful natural gas gas consumers that have been assigned to the gas and out of the  continuing to the contact information in the new building.\n",
            "The team is to pursue our call yesterday to participate in the Commission and the commercial team to perform the restricted account with the contracts before your best people will be sure that you are not in the present to the draft of the PA and I will be provided to the Enron Corp. San Diego to the following the term sheet to be attending a massive under the Star Conference to  accomplish the company (10 days) and we are currently in  the office of the Californ \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 2.7599594593048096\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['The', 'The', 'The', 'The', 'The'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result, '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AugyZlBu7RUg",
        "outputId": "58852dae-e769-4b39-84a9-ac06e59c087b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'The outside contest can be determined at the  fact of the entire company.\\nThe person will be out of the office and then mentioned to the continued markets.\\nI have asked you to pass the Enron short and possible  and speak with your Enron has another trading on the Enron Corp. Savings Plan address for the YPR market.\\nAs part of the consumer the comments which we will be offers and the public accounts from the Conference Room.\\nWe need to have a contribution to the policy  in the new database.\\nThis is the first month to get some time to sign the greatest contact list of the press that I wanted to make sure that the schedule will be done to take a look at the phone given the deadline for a different day.\\nThis is the list with the contracts that we can send the confirmation from the company with the security such actions for the extent that we can receive an executed form of agreement with the Master Agreement.\\nIn the meantime, the continued car concerns are the counterparty party to me for the'\n",
            " b'The schedule under the process of the presentations of the proposal in the Commission to explain the Assistants Group.\\nPlease RSVP to the Commercial Data Company and San Peak-poputary                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    '\n",
            " b'The conference consultant to help make the surprise of the version of the general process from the team to take any reason that you cannot be in touch with the funds to complete a  summary for the section of the schedule of the deal.\\nI will get the big thing for the contact information with the Senate with the original survey of the program and return on the past two three years and return it to me via fax no.\\n(713) 853-3491 (as I have to make a chance to review the attached and address the contacted message from Mark Palmers.\\nI am sure that the transaction has been included as the current discussion with the Sunday of the day and how the dead horse do have been severed by the product of the program for such a couple of days to take a moment to  attend  to discuss the curves to develop and receive a copy of the direction and confirm your pay out to your home address.\\nThanks for your help and please feel free to call me at (713) 853-6399.\\nThanks,\\nI apologize for a conference call and ask t'\n",
            " b'The workshop are as facilities in programs of Transwestern you would like to replace the proposal for the first time in the future.\\nI am not completing the contract for the suites of the changes with the possibility of the  week of Foundation except the settlement and the regional transactions with the  trading of the possibility and continue to be another number on the schedule of the meeting with Section 3.2 and are now available to cover the call and complete the attached access for the only origination of the termination party.\\nThe similar process is the period of the program and the term sheet.\\nThe confirming process will be considered by the changes to the Advice Community Corporation and our continued subsidiaries of the Public Relations in Australia for Enron North Americas and Enron Corp.  Corporation District of Power Trading Carolina Gas and Power Pool, Inc. the cost of the process.\\nThe transaction will be help desk for the following person will be hosting to the Enron Corp. Sa'\n",
            " b'The Energy Committee meeting will be helping up and the trading group will be assuming that its plan will be prepared to fix the process of our community.\\nThe confidentiality of our customers will be available in the past the counterparty will continue to reduce the process and the same person would busy and the company needs to be paid on the weekend.\\nThanks for your help.\\nThe good role of the progress is the  gas and power plant was definitely in the process of sending a draft of the Asspective Agreement to the extent that includes the posting before and optimize the particular volume of the appropriate personal information on the subject to the deal flow of the program or financial product.\\nThe tentative successful electricity aggregate of the potential effort and the regulatory agreement is to conference the only confirmation should be made available on Lexis-Nexis.\\nAttend our Lexis-Nexis Basics Online Clinic:   November 14\\t10:00 AM Central Standard Time (US & Canada).\\nWhere: EB 38C1 '], shape=(5,), dtype=string) \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 2.6510770320892334\n"
          ]
        }
      ]
    }
  ]
}
