{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DanB1421/DATA602/blob/main/Week_11_Problem_Set%20%20%20%20%20%20%20%20%20%20%20%20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZJo1f8qJd4-"
      },
      "source": [
        "Rock Paper Scissors is a classic hand game where players compete through using hand gestures (see [Wikipedia](https://en.wikipedia.org/wiki/Rock\\_paper\\_scissors)).  The Tensorflow-datasets package provides a\n",
        "library of hand gestures corresponding to allowed gestures in the game.  The original source is a synthetic data source, via Laurence Maroney ([source](https://laurencemoroney.com/datasets.html\\#rock-paper-scissors-dataset)).\n",
        "\n",
        "Write a convolutional neural network (CNN) that classifies these images, i.e., identifies the gesture (rock, paper, scissors) from each source image.  For convenience, this template is provided for loading the dataset and for data augmentation.  Feel free to make any changes to this template code.  Try to achieve a validation accuracy rate of 90\\% or above.\n",
        "\n",
        "You may make use of pretrained CNN architectures in Keras or develop your own.  If you develop your own, you are encouraged to review the network architectures discussed in class (e.g., LeNet and AlexNet).  If you use a pretrained architecture, refer to the [Transfer Learning and fine-tuning](https://keras.io/guides/transfer_learning/) developer guide on the Keras website.  \n",
        "\n",
        "Because the training dataset is relatively small, you may need to employ techniques such as regularization and data augmentation to achieve a high accuracy rate.  Code for data augmentation is included in the template.\n",
        "\n",
        "Using a graphics card is highly recommended when fitting the model.  You can set Colab to use the graphics card in Runtime $\\rightarrow$ Manage Settings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BaUTGarJ_3y"
      },
      "source": [
        "# Preamble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1N2gG3fuxd_-"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "from functools import partial\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYKGUOjWUoxW"
      },
      "source": [
        "#Data loading and preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWuuMRnEKW1k"
      },
      "source": [
        "We first load the test dataset from tensorflow datasets (TFDS).  The original set has only training and validation sets, so we shuffle the dataset here to produce training, validation, and validation sets.\n",
        "\n",
        "* [Documentation for `tfds.load`](https://www.tensorflow.org/datasets/api_docs/python/tfds/load)\n",
        "* [Rock Paper Scissors dataset](https://www.tensorflow.org/datasets/catalog/rock_paper_scissors)\n",
        "* [TFDS images in this dataset](https://knowyourdata-tfds.withgoogle.com/#tab=STATS&dataset=rock_paper_scissors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JC_GHwVrx2ZS"
      },
      "outputs": [],
      "source": [
        "(ds_orig, ds_val_orig, ds_test_orig), dsinfo = tfds.load(\n",
        "    'rock_paper_scissors',\n",
        "    split=(\"test+train[60%:]\", \"train[60%:80%]\", \"train[80%:]\"),\n",
        "    with_info=True,\n",
        "    as_supervised=True,\n",
        "    shuffle_files=False)\n",
        "\n",
        "labelnames = dsinfo.features['label'].names"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below are constants, configure as needed."
      ],
      "metadata": {
        "id": "mKPN-A5bRbw1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 8   # size of mini-batch\n",
        "image_size = 128  # size of image to feed into network\n",
        "n_repeat = 5 # number of times to repeat the input dataset with distorted images"
      ],
      "metadata": {
        "id": "uk2qT654Rf2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTSHQVUEL9Vb"
      },
      "source": [
        "We create a convenience function, `show_sample_images` to show 10 random images from the set.  Example usage: `show_sample_images(ds_orig)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDpj4O7C1WaJ"
      },
      "outputs": [],
      "source": [
        "def show_sample_images(ds):\n",
        "  fig, axs = plt.subplots(4, 4, figsize=(10,10))\n",
        "  for ax, k in zip(np.array(axs).ravel(), ds.unbatch().shuffle(128).take(16)):\n",
        "      ax.imshow(k[0])\n",
        "      ax.set_title(labelnames[k[1]])\n",
        "  fig.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCxuMaKWMapi"
      },
      "source": [
        "We will need to perform some preprocessing.  The below preprocessing function is a starting point.\n",
        "\n",
        "* `distort` is a network that performs image augmentation.  For input images, it will randomly provide distortions such as distorting contrast, zooming in or out, rotation, and translation.  Passing an image into this network will apply these distortions.  Refer to documentation for these functions [here](https://www.tensorflow.org/api_docs/python/tf/image).\n",
        "\n",
        "* `preproc` is a preprocessing function that accepts an image and label, and can apply updates to both (similar to a FunctionTransformer in scikit).  We only apply distortions if augment is true (as we will see, we want to apply to the training dataset).  \n",
        "\n",
        "   Preproc also converts the image to grayscale, which provides some performance improvement since color is not expected important for processing.  If you remove grayscale conversion, remember to change the depth of the input layer from 1 to 3.\n",
        "\n",
        "  Finally, preproc rescales the image from 0-255 to 0-1 ([`convert_image_dtype`](https://www.tensorflow.org/api_docs/python/tf/image/convert_image_dtype)) and resizes the image.\n",
        "\n",
        "  * We also create two wrapper functions, `preproc_no_distort` and `preproc_distort`, for later compatibility with the tensor flow's data object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kFsq7oxh2Lub"
      },
      "outputs": [],
      "source": [
        "distort = keras.Sequential(\n",
        "    [\n",
        "    keras.layers.RandomContrast(0.2),\n",
        "    keras.layers.RandomZoom((-.05, .05), fill_mode='nearest'),\n",
        "    keras.layers.RandomRotation((-.04, .04), fill_mode='nearest'),\n",
        "    keras.layers.RandomTranslation(0, (-.2, .2), fill_mode='nearest')\n",
        "    ]\n",
        ")\n",
        "def preproc(image, label, augment):\n",
        "  if augment:\n",
        "    image = distort(image)/255.0\n",
        "  #image = tf.image.rgb_to_grayscale(image)\n",
        "  image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "  image = tf.image.resize(image, (image_size, image_size))\n",
        "  return image, label\n",
        "\n",
        "def preproc_no_distort(image, label):\n",
        "  return preproc(image, label, False)\n",
        "\n",
        "def preproc_distort(image, label):\n",
        "  return preproc(image, label, True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHrxFAOIPqvj"
      },
      "source": [
        "We can now prepare the datasets.  For the three datasets defined above (training, validation, and test), we preprocess each element using the `map` function.  (See [guidelines for TensorFlow input pipelines](https://www.tensorflow.org/guide/data) and [`tf.data.Dataset` documentation](https://www.tensorflow.org/api_docs/python/tf/data/Dataset).  From the texts, see also chapter 13 in Raschka and chapter 11 in Geron.  We also break the training set into minibatches.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OznPbhxKOnBW"
      },
      "outputs": [],
      "source": [
        "ds = ds_orig.map(preproc_distort).batch(batch_size)\n",
        "ds_val = ds_val_orig.map(preproc_no_distort).batch(1)\n",
        "ds_test = ds_test_orig.map(preproc_no_distort).batch(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiDvRfPoRWnL"
      },
      "source": [
        "# Build Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lzy1dnW-RV-o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4e21cd1-9466-4632-9efd-71511edbd1be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 2048)              23587712  \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 1024)              2098176   \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 3)                 3075      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,688,963\n",
            "Trainable params: 2,101,251\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Write and compile the model here\n",
        "\n",
        "pretrained_model = keras.applications.resnet50.ResNet50(include_top=False,\n",
        "                            input_shape=(image_size, image_size, 3),\n",
        "                            pooling=\"max\")\n",
        "pretrained_model.trainable = False\n",
        "\n",
        "model = Sequential([\n",
        "    pretrained_model,\n",
        "    Dense(1024, activation=\"elu\"),\n",
        "    Dense(3, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.Nadam(),\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=['accuracy'])\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rc7tIjJkRdKu"
      },
      "source": [
        "# Fit\n",
        "\n",
        "We have two callbacks:\n",
        "\n",
        "* `ModelCheckpoint`, which saves the model after each mini-batch.  We set the `save_best_only` parameter so that if the model performance deteriorates, we only keep the weights from the best-performing batch.\n",
        "\n",
        "* `EarlyStopping`, which stops the model after no improvement for four iterations.\n",
        "\n",
        "Note that we repeat the dataset here by calling `ds.repeat(n_repeat)`.  Because we are using image augmentation, this allows the network to be trained on multiple variants of each distorted image.\n",
        "\n",
        "**Remember to change the runtime type to GPU before running (Change Runtime Type under the Tools menu.)**  You will need to re-run the notebook after changing the runtime type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTM1uRdYRcsW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "592b9c3b-04cb-43cb-e68e-d1e4eaa7696b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "865/865 [==============================] - 183s 205ms/step - loss: 0.3247 - accuracy: 0.8732 - val_loss: 0.0640 - val_accuracy: 0.9881\n",
            "Epoch 2/20\n",
            "865/865 [==============================] - 178s 206ms/step - loss: 0.1753 - accuracy: 0.9336 - val_loss: 0.0185 - val_accuracy: 0.9960\n",
            "Epoch 3/20\n",
            "865/865 [==============================] - 175s 203ms/step - loss: 0.1553 - accuracy: 0.9436 - val_loss: 0.0876 - val_accuracy: 0.9722\n",
            "Epoch 4/20\n",
            "865/865 [==============================] - 176s 203ms/step - loss: 0.1399 - accuracy: 0.9516 - val_loss: 0.0166 - val_accuracy: 0.9960\n",
            "Epoch 5/20\n",
            "865/865 [==============================] - 175s 202ms/step - loss: 0.1280 - accuracy: 0.9535 - val_loss: 0.0479 - val_accuracy: 0.9802\n",
            "Epoch 6/20\n",
            "865/865 [==============================] - 174s 201ms/step - loss: 0.1130 - accuracy: 0.9577 - val_loss: 0.1250 - val_accuracy: 0.9603\n"
          ]
        }
      ],
      "source": [
        "earlystopping = keras.callbacks.EarlyStopping(min_delta=0.005, patience=4)\n",
        "checkpoint = keras.callbacks.ModelCheckpoint(\"mdl-rps-eval-gap.h5\", save_best_only=True)\n",
        "dsr = ds.repeat(n_repeat) if n_repeat > 0 else ds\n",
        "history = model.fit(dsr, validation_data=ds_val, epochs=20,\n",
        "                    callbacks=[earlystopping, checkpoint])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDBYIulvTMWP"
      },
      "source": [
        "#  Evaluate\n",
        "\n",
        "We evaluate the best-performing model (saved in the model checkpoint callback) against the test dataset.  Recall that we are looking for an accuracy of 0.9 or above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PXoAEkGdS61H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd3de143-7647-4ec5-b63c-a55c908ed132"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "504/504 [==============================] - 7s 11ms/step - loss: 0.0237 - accuracy: 0.9901\n",
            "0.9900793433189392\n"
          ]
        }
      ],
      "source": [
        "model = keras.models.load_model(\"mdl-rps-eval-gap.h5\")\n",
        "_, accuracy = model.evaluate(ds_test)\n",
        "print(accuracy)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
